{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969be8ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:32\u001b[1;36m\u001b[0m\n\u001b[1;33m    torch.save({\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = \"/Deepfake/code/FF++/\"\n",
    "train_dataset_path = os.path.join(dataset_path, \"Train\")\n",
    "test_dataset_path = os.path.join(dataset_path, \"Test\")\n",
    "\n",
    "\n",
    "start_epoch = 24\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\" Resumed training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\" No checkpoint found. Starting fresh training.\")\n",
    "   torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "    }, os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth'))\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "full_dataset = ImageFolder(root=train_dataset_path)\n",
    "test_dataset = ImageFolder(root=test_dataset_path)\n",
    "\n",
    "# Define transformations\n",
    "IMG_SIZE = 224\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply transforms\n",
    "full_dataset.transform = train_transforms\n",
    "test_dataset.transform = val_transforms\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Model Architecture\n",
    "class HybridDeepfakeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.effnet = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        self.effnet.classifier = nn.Identity()\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        self.vit.head = nn.Identity()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.effnet(x)\n",
    "        vit_features = self.vit(x)\n",
    "        combined_features = torch.cat([eff_features, vit_features], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\n",
    "# Initialize model\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridDeepfakeDetector().to(DEVICE)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=2)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.float().to(DEVICE).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss / len(train_loader.dataset):.4f}\")\n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "# Model Evaluation\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_score(true_labels, np.round(predictions))\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, np.round(predictions))\n",
    "    precision = precision_score(true_labels, np.round(predictions))\n",
    "    recall = recall_score(true_labels, np.round(predictions))\n",
    "    return accuracy, auc, f1, precision, recall\n",
    "\n",
    "accuracy, auc, f1, precision, recall = evaluate_model(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "# Single Image Prediction\n",
    "def predict(image_path, model):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = val_transforms(image).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        prediction = torch.sigmoid(output).item()\n",
    "    return \"Fake\" if prediction > 0.5 else \"Real\"\n",
    "\n",
    "# Example usage\n",
    "print(predict(\"/content/testimage deepfake.jpg\", model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b996247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_20944\\1655890072.py:52: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "c:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed training from epoch 20\n",
      "Training samples: 2012\n",
      "Validation samples: 504\n",
      "Test samples: 3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_20944\\1655890072.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "c:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 - Train Loss: 0.1868\n",
      "Epoch 22/30 - Train Loss: 0.1872\n",
      "Epoch 23/30 - Train Loss: 0.1891\n",
      "Epoch 24/30 - Train Loss: 0.1955\n",
      "Epoch 25/30 - Train Loss: 0.1939\n",
      "Epoch 26/30 - Train Loss: 0.1916\n",
      "Epoch 27/30 - Train Loss: 0.1843\n",
      "Epoch 28/30 - Train Loss: 0.1848\n",
      "Epoch 29/30 - Train Loss: 0.1943\n",
      "Epoch 30/30 - Train Loss: 0.1918\n",
      "Test Accuracy: 0.9296\n",
      "Test AUC: 1.0000\n",
      "Test F1 Score: 0.9167\n",
      "Test Precision: 0.8462\n",
      "Test Recall: 1.0000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\content\\\\testimage_deepfake.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 172\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFake\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReal\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28mprint\u001b[39m(predict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/testimage_deepfake.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, model))\n",
      "Cell \u001b[1;32mIn[1], line 164\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(image_path, model)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(image_path, model):\n\u001b[0;32m    163\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m--> 164\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    165\u001b[0m     image \u001b[38;5;241m=\u001b[39m val_transforms(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\A\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\content\\\\testimage_deepfake.jpg'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "import os\n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = \"/Deepfake/code/FF++/\"\n",
    "train_dataset_path = os.path.join(dataset_path, \"Train\")\n",
    "test_dataset_path = os.path.join(dataset_path, \"Test\")\n",
    "\n",
    "# Device setup\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model Architecture\n",
    "class HybridDeepfakeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.effnet = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        self.effnet.classifier = nn.Identity()\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        self.vit.head = nn.Identity()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.effnet(x)\n",
    "        vit_features = self.vit(x)\n",
    "        combined_features = torch.cat([eff_features, vit_features], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = HybridDeepfakeDetector().to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Checkpoint resume logic\n",
    "checkpoint_path = \"checkpoint_epoch_19.pth\"  # update if using different file\n",
    "start_epoch = 20\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh training.\")\n",
    "\n",
    "# Transforms\n",
    "IMG_SIZE = 224\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load and prepare datasets\n",
    "full_dataset = ImageFolder(root=train_dataset_path)\n",
    "test_dataset = ImageFolder(root=test_dataset_path)\n",
    "\n",
    "full_dataset.transform = train_transforms\n",
    "test_dataset.transform = val_transforms\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Training Loop with Checkpointing\n",
    "EPOCHS = 30\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.float().to(DEVICE).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {avg_loss:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "    # âœ… Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "    }, f'checkpoint_epoch_{epoch}.pth')\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, np.round(predictions))\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, np.round(predictions))\n",
    "    precision = precision_score(true_labels, np.round(predictions))\n",
    "    recall = recall_score(true_labels, np.round(predictions))\n",
    "    return accuracy, auc, f1, precision, recall\n",
    "\n",
    "accuracy, auc, f1, precision, recall = evaluate_model(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "# Single image prediction\n",
    "def predict(image_path, model):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = val_transforms(image).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        prediction = torch.sigmoid(output).item()\n",
    "    return \"Fake\" if prediction > 0.5 else \"Real\"\n",
    "\n",
    "# Example usage\n",
    "print(predict(\"/content/testimage_deepfake.jpg\", model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
