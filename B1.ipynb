{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa4a80f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2012\n",
      "Validation samples: 504\n",
      "Test samples: 3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_9916\\1317453136.py:99: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "c:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed training from epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_9916\\1317453136.py:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(\"cuda\"):\n",
      "c:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train Loss: 0.0064\n",
      "Epoch 12/20 - Train Loss: 0.0014\n",
      "Epoch 13/20 - Train Loss: 0.0012\n",
      "Epoch 14/20 - Train Loss: 0.0021\n",
      "Epoch 15/20 - Train Loss: 0.0006\n",
      "Epoch 16/20 - Train Loss: 0.0010\n",
      "Epoch 17/20 - Train Loss: 0.0002\n",
      "Epoch 18/20 - Train Loss: 0.0023\n",
      "Epoch 19/20 - Train Loss: 0.0010\n",
      "Epoch 20/20 - Train Loss: 0.0004\n",
      "Test Accuracy: 0.9091\n",
      "Test AUC: 0.9995\n",
      "Test F1 Score: 0.8950\n",
      "Test Precision: 0.8099\n",
      "Test Recall: 1.0000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/multiple_test_images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 200\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Example multiple image usage\u001b[39;00m\n\u001b[0;32m    199\u001b[0m image_folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/multiple_test_images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 200\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predict_multiple(image_folder_path, model)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_name, result \u001b[38;5;129;01min\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 183\u001b[0m, in \u001b[0;36mpredict_multiple\u001b[1;34m(images_dir, model)\u001b[0m\n\u001b[0;32m    181\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    182\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(images_dir):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    185\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(images_dir, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/multiple_test_images/'"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = \"/Deepfake/code/FF++/\"\n",
    "train_dataset_path = os.path.join(dataset_path, \"Train\")\n",
    "test_dataset_path = os.path.join(dataset_path, \"Test\")\n",
    "\n",
    "# Load datasets\n",
    "full_dataset = ImageFolder(root=train_dataset_path)\n",
    "test_dataset = ImageFolder(root=test_dataset_path)\n",
    "\n",
    "# Define transformations\n",
    "IMG_SIZE = 224\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # Random rotation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply transforms\n",
    "full_dataset.transform = train_transforms\n",
    "test_dataset.transform = val_transforms\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Model Architecture with Ensemble\n",
    "class EnsembleDeepfakeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.effnet = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.DEFAULT)\n",
    "        self.effnet.classifier = nn.Identity()  # Remove the classifier\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        self.vit.head = nn.Identity()  # Remove the head\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.resnet.fc = nn.Identity()  # Remove the final fully connected layer\n",
    "        \n",
    "        # Calculate the output sizes\n",
    "        effnet_output_size = 1280  # EfficientNet-B1 output size\n",
    "        vit_output_size = 768  # ViT output size\n",
    "        resnet_output_size = 2048  # ResNet50 output size\n",
    "        \n",
    "        # Adjust the input size for the classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(effnet_output_size + vit_output_size + resnet_output_size, 128),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.effnet(x)\n",
    "        vit_features = self.vit(x)\n",
    "        resnet_features = self.resnet(x)\n",
    "        combined_features = torch.cat([eff_features, vit_features, resnet_features], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\n",
    "# Device, model, loss, optimizer\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EnsembleDeepfakeDetector().to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=2)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Resume training if checkpoint exists\n",
    "checkpoint_path = \"checkpoint_epoch_9.pth\"\n",
    "start_epoch = 10\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh training.\")\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.float().to(DEVICE).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss / len(train_loader.dataset):.4f}\")\n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "    }, f'checkpoint_epoch_{epoch}.pth')\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_score(true_labels, np.round(predictions))\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, np.round(predictions))\n",
    "    precision = precision_score(true_labels, np.round(predictions))\n",
    "    recall = recall_score(true_labels, np.round(predictions))\n",
    "    return accuracy, auc, f1, precision, recall\n",
    "\n",
    "accuracy, auc, f1, precision, recall = evaluate_model(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "# Predict single image\n",
    "#def predict(image_path, model):\n",
    "    #model.eval()\n",
    "   # image = Image.open(image_path).convert(\"RGB\")\n",
    "   # image = val_transforms(image).unsqueeze(0).to(DEVICE)\n",
    "   # with torch.no_grad():\n",
    "   #     output = model(image)\n",
    "   #     prediction = torch.sigmoid(output).item()\n",
    "   # return \"Fake\" if prediction > 0.5 else \"Real\"\n",
    "\n",
    "# Example single image\n",
    "#print(predict(\"/content/testimage_deepfake.jpg\", model))\n",
    "\n",
    "# Predict multiple images\n",
    "def predict_multiple(images_dir, model):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    for filename in os.listdir(images_dir):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = os.path.join(images_dir, filename)\n",
    "            try:\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                image = val_transforms(image).unsqueeze(0).to(DEVICE)\n",
    "                with torch.no_grad():\n",
    "                    output = model(image)\n",
    "                    prediction = torch.sigmoid(output).item()\n",
    "                label = \"Fake\" if prediction > 0.5 else \"Real\"\n",
    "                results[filename] = (label, round(prediction, 4))\n",
    "            except Exception as e:\n",
    "                results[filename] = f\"Error: {e}\"\n",
    "    return results\n",
    "\n",
    "# Example multiple image usage\n",
    "image_folder_path = \"/content/multiple_test_images/\"\n",
    "predictions = predict_multiple(image_folder_path, model)\n",
    "for image_name, result in predictions.items():\n",
    "    print(f\"{image_name}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eaebba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2012\n",
      "Validation samples: 504\n",
      "Test samples: 3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_18620\\2277575716.py:102: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "c:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed training from epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_18620\\2277575716.py:125: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(\"cuda\"):\n",
      "c:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Train Loss: 0.0234\n",
      "Epoch 16/20 - Train Loss: 0.0556\n",
      "Epoch 17/20 - Train Loss: 0.0260\n",
      "Epoch 18/20 - Train Loss: 0.0128\n",
      "Epoch 19/20 - Train Loss: 0.0296\n",
      "Epoch 20/20 - Train Loss: 0.0324\n",
      "Test Accuracy: 0.9578\n",
      "Test AUC: 1.0000\n",
      "Test F1 Score: 0.9483\n",
      "Test Precision: 0.9017\n",
      "Test Recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = \"/Deepfake/code/FF++/\"\n",
    "train_dataset_path = os.path.join(dataset_path, \"Train\")\n",
    "test_dataset_path = os.path.join(dataset_path, \"Test\")\n",
    "\n",
    "# Load datasets\n",
    "full_dataset = ImageFolder(root=train_dataset_path)\n",
    "test_dataset = ImageFolder(root=test_dataset_path)\n",
    "\n",
    "# Define transformations\n",
    "IMG_SIZE = 224\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # Random rotation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply transforms\n",
    "full_dataset.transform = train_transforms\n",
    "test_dataset.transform = val_transforms\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Model Architecture with Ensemble\n",
    "class EnsembleDeepfakeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.effnet = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.DEFAULT)\n",
    "        self.effnet.classifier = nn.Identity()  # Remove the classifier\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        self.vit.head = nn.Identity()  # Remove the head\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.resnet.fc = nn.Identity()  # Remove the final fully connected layer\n",
    "        \n",
    "        # Calculate the output sizes\n",
    "        effnet_output_size = 1280  # EfficientNet-B1 output size\n",
    "        vit_output_size = 768  # ViT output size\n",
    "        resnet_output_size = 2048  # ResNet50 output size\n",
    "        \n",
    "        # Adjust the input size for the classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4096, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.effnet(x)\n",
    "        vit_features = self.vit(x)\n",
    "        resnet_features = self.resnet(x)\n",
    "        combined_features = torch.cat([eff_features, vit_features, resnet_features], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\n",
    "# Device, model, loss, optimizer\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EnsembleDeepfakeDetector().to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=2)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Resume training if checkpoint exists\n",
    "checkpoint_path = \"checkpoint_epoch_13.pth\"\n",
    "start_epoch = 14\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh training.\")\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.float().to(DEVICE).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss / len(train_loader.dataset):.4f}\")\n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "    }, f'checkpoint_epoch_{epoch}.pth')\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_score(true_labels, np.round(predictions))\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, np.round(predictions))\n",
    "    precision = precision_score(true_labels, np.round(predictions))\n",
    "    recall = recall_score(true_labels, np.round(predictions))\n",
    "    return accuracy, auc, f1, precision, recall\n",
    "\n",
    "accuracy, auc, f1, precision, recall = evaluate_model(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Predict multiple images\n",
    "def predict_multiple(images_dir, model):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    for filename in os.listdir(images_dir):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = os.path.join(images_dir, filename)\n",
    "            try:\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                image = val_transforms(image).unsqueeze(0).to(DEVICE)\n",
    "                with torch.no_grad():\n",
    "                    output = model(image)\n",
    "                    prediction = torch.sigmoid(output).item()\n",
    "                label = \"Fake\" if prediction > 0.5 else \"Real\"\n",
    "                results[filename] = (label, round(prediction, 4))\n",
    "            except Exception as e:\n",
    "                results[filename] = f\"Error: {e}\"\n",
    "    return results\n",
    "\n",
    "# Example multiple image usage\n",
    "image_folder_path = \"/Deepfake/code/Multiple_outputs\"\n",
    "predictions = predict_multiple(image_folder_path, model)\n",
    "for image_name, result in predictions.items():\n",
    "    print(f\"{image_name}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9938c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 9306\n",
      "Validation samples: 2327\n",
      "Test samples: 2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_19764\\1309443302.py:101: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "c:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_19764\\1309443302.py:124: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(\"cuda\"):\n",
      "c:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found. Starting fresh training.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 127\u001b[0m\n\u001b[0;32m    125\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m    126\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m--> 127\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    128\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    129\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    628\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[0;32m    348\u001b[0m     tensors,\n\u001b[0;32m    349\u001b[0m     grad_tensors_,\n\u001b[0;32m    350\u001b[0m     retain_graph,\n\u001b[0;32m    351\u001b[0m     create_graph,\n\u001b[0;32m    352\u001b[0m     inputs,\n\u001b[0;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    355\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\A\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = \"/Deepfake/code/Combined(FF+&Celeb-DF)\"\n",
    "train_dataset_path = os.path.join(dataset_path, \"Train\")\n",
    "test_dataset_path = os.path.join(dataset_path, \"Test\")\n",
    "\n",
    "# Load datasets\n",
    "full_dataset = ImageFolder(root=train_dataset_path)\n",
    "test_dataset = ImageFolder(root=test_dataset_path)\n",
    "\n",
    "# Define transformations\n",
    "IMG_SIZE = 224\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # Random rotation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Color jitter\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random affine transformation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply transforms\n",
    "full_dataset.transform = train_transforms\n",
    "test_dataset.transform = val_transforms\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "val_dataset.dataset.transform = val_transforms\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Model Architecture with Ensemble\n",
    "class EnsembleDeepfakeDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.effnet = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.DEFAULT)\n",
    "        self.effnet.classifier = nn.Identity()  # Remove the classifier\n",
    "        self.vit = timm.create_model(\"vit_base_patch16_224\", pretrained=True)\n",
    "        self.vit.head = nn.Identity()  # Remove the head\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.resnet.fc = nn.Identity()  # Remove the final fully connected layer\n",
    "        \n",
    "        # Calculate the output sizes\n",
    "        effnet_output_size = 1280  # EfficientNet-B1 output size\n",
    "        vit_output_size = 768  # ViT output size\n",
    "        \n",
    "        # Adjust the input size for the classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(4096, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        eff_features = self.effnet(x)\n",
    "        vit_features = self.vit(x)\n",
    "        resnet_features = self.resnet(x)\n",
    "        combined_features = torch.cat([eff_features, vit_features, resnet_features], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\n",
    "# Device, model, loss, optimizer\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EnsembleDeepfakeDetector().to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=2)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Resume training if checkpoint exists\n",
    "checkpoint_path = \"checkpoint_epoch_0.pth\"\n",
    "start_epoch = 0\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh training.\")\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 20\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.float().to(DEVICE).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast(\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        torch.cuda.empty_cache()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss / len(train_loader.dataset):.4f}\")\n",
    "    scheduler.step(train_loss)\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "    }, f'checkpoint_epoch_{epoch}.pth')\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy().flatten()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_score(true_labels, np.round(predictions))\n",
    "    auc = roc_auc_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, np.round(predictions))\n",
    "    precision = precision_score(true_labels, np.round(predictions))\n",
    "    recall = recall_score(true_labels, np.round(predictions))\n",
    "    return accuracy, auc, f1, precision, recall\n",
    "\n",
    "accuracy, auc, f1, precision, recall = evaluate_model(model, test_loader)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test AUC: {auc:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Predict multiple images\n",
    "def predict_multiple(images_dir, model):\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    for filename in os.listdir(images_dir):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = os.path.join(images_dir, filename)\n",
    "            try:\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                image = val_transforms(image).unsqueeze(0).to(DEVICE)\n",
    "                with torch.no_grad():\n",
    "                    output = model(image)\n",
    "                    prediction = torch.sigmoid(output).item()\n",
    "                label = \"Fake\" if prediction > 0.5 else \"Real\"\n",
    "                results[filename] = (label, round(prediction, 4))\n",
    "            except Exception as e:\n",
    "                results[filename] = f\"Error: {e}\"\n",
    "    return results\n",
    "\n",
    "# Example multiple image usage\n",
    "image_folder_path = \"/Deepfake/code/Multiple_outputs\"\n",
    "predictions = predict_multiple(image_folder_path, model)\n",
    "for image_name, result in predictions.items():\n",
    "    print(f\"{image_name}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
